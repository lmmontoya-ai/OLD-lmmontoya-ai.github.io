[
  {
    "title": "Welcome to My AI Journey: From Physics to Machine Learning",
    "slug": "introduction",
    "excerpt": "An introduction to my background in physics, transition to AI research, and passion for interpretability and alignment. Join me as I document my learning journey and share insights.",
    "content": "Hello, and Welcome! I'm Luis Miguel Montoya, and I'm excited to share my journey into the fascinating world of artificial intelligence with you. This blog serves as both a learning log and a way to connect with others who share my passion for understanding how AI systems work and ensuring they align with human values. My Background: A Physicist's Path to AI My journey began in physics, where I developed a deep appreciation for mathematical rigor and systematic problem-solving. The transition from studying the fundamental laws of nature to understanding artificial minds might seem like a leap, but there's more overlap than you might think. Physics taught me to: Think in systems - Understanding how complex behaviors emerge from simple rules Embrace uncertainty - Working with probabilistic models and statistical mechanics Value interpretability - Always asking \"why does this work?\" rather than just \"does it work?\" Pursue first principles - Breaking down complex problems into fundamental c",
    "types": [
      "blog"
    ],
    "category": "Reflection",
    "tags": [
      "Introduction",
      "AI",
      "Physics",
      "Career",
      "Personal"
    ],
    "date": "2025-05-30T00:00:00.000Z",
    "href": "/posts/introduction"
  },
  {
    "title": "Testing Search Functionality: AI Safety and Interpretability",
    "slug": "test-search",
    "excerpt": "A comprehensive test post for search functionality, covering various AI safety and interpretability topics to validate search indexing and retrieval.",
    "content": "Search Test Introduction This post serves as a comprehensive test for the search functionality of this site. It contains a diverse range of content related to AI safety, interpretability, and machine learning to validate that the search indexing and retrieval systems work correctly across different topics and content types. AI Safety Concepts Alignment Problem The AI alignment problem refers to the challenge of ensuring that artificial intelligence systems pursue goals that are aligned with human values and intentions. This is particularly important as AI systems become more capable and autonomous. Key aspects of alignment include: Value alignment: Ensuring AI systems optimize for human-preferred outcomes Intent alignment: Making sure AI systems do what humans want them to do Robustness: Maintaining alignment under distribution shift and novel circumstances Constitutional AI Constitutional AI is an approach developed by Anthropic that trains AI systems to be helpful, harmless, and hone",
    "types": [
      "blog",
      "note"
    ],
    "category": "Technical",
    "tags": [
      "Search",
      "Testing",
      "AI Safety",
      "Interpretability",
      "Machine Learning",
      "Neural Networks",
      "Transformers",
      "Alignment"
    ],
    "date": "2024-03-20T00:00:00.000Z",
    "href": "/posts/test-search"
  },
  {
    "title": "Literature Review: Attention is All You Need",
    "slug": "test-literature-attention",
    "excerpt": "Comprehensive review of the landmark transformer paper that revolutionized natural language processing and became the foundation for modern LLMs.",
    "content": "Paper Summary The \"Attention is All You Need\" paper introduced the Transformer architecture, which has become the foundation for most modern large language models including GPT, BERT, and their variants. This groundbreaking work demonstrated that attention mechanisms alone, without recurrence or convolution, could achieve state-of-the-art results in sequence-to-sequence tasks. Key Contributions Pure Attention Architecture The paper showed that recurrent and convolutional layers are not necessary for achieving excellent performance on sequence transduction tasks. The Transformer relies entirely on attention mechanisms to draw global dependencies between input and output. Multi-Head Attention Instead of performing a single attention function, the model uses multiple \"attention heads\" that learn different types of relationships: Some heads focus on syntactic relationships Others capture semantic dependencies Some specialize in long-range dependencies Positional Encoding Since the model ha",
    "types": [
      "literature",
      "note"
    ],
    "category": "Research",
    "tags": [
      "Transformers",
      "Attention",
      "Deep Learning",
      "Paper Review",
      "NLP"
    ],
    "date": "2024-03-08T00:00:00.000Z",
    "href": "/posts/test-literature-attention"
  }
]